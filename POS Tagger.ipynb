{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52df65fc",
   "metadata": {},
   "source": [
    "importing json module and reading data as well as checking type, format of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff50e2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words is: 81147\n",
      "Most used tag is:  NN\n",
      "It is used for 12721 times \n",
      "total number of tags in dataset is:  41\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from time import time\n",
    "import random\n",
    "tag_count={}\n",
    "now=time()\n",
    "f = open('penn-data.json')\n",
    "data = json.load(f)\n",
    "#print(data)\n",
    "#random.shuffle(data)\n",
    "for point in data:\n",
    "    tags=point[1]\n",
    "    for tag in tags:\n",
    "        if tag not in tag_count:\n",
    "            tag_count[tag]=1\n",
    "        else:\n",
    "            tag_count[tag]+=1\n",
    "freq=0\n",
    "most_used_tag=''\n",
    "total=0\n",
    "for tag,count in tag_count.items():\n",
    "    total+=count\n",
    "    if count>freq:\n",
    "        freq=count\n",
    "        most_used_tag=tag\n",
    "        \n",
    "print('Total number of words is:',total )        \n",
    "print('Most used tag is: ',most_used_tag)\n",
    "print(f'It is used for {freq} times ')\n",
    "print(\"total number of tags in dataset is: \",len(tag_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26209d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples:  3914\n",
      "No. of training examples:  3131\n",
      "No. of testing examples:  783\n"
     ]
    }
   ],
   "source": [
    "train_nos=round(0.8*len(data))\n",
    "print('Total number of examples: ',len(data))\n",
    "print('No. of training examples: ',train_nos)\n",
    "test_nos=len(data)-train_nos\n",
    "print('No. of testing examples: ',test_nos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7fde9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict={'<start>':0}\n",
    "tag_dict={'<start>':0}\n",
    "word_count=1\n",
    "tag_count=1\n",
    "seq_file = open(\"seq.txt\",\"w\")\n",
    "tag_file=open(\"tag.txt\",\"w\")\n",
    "for tag_seq in data:\n",
    "    seq=tag_seq[0].split(' ')\n",
    "    tag=tag_seq[1]\n",
    "    for i in range(len(seq)):\n",
    "        seq[i]=seq[i].lower()\n",
    "        if \"'\" in seq[i]:\n",
    "            seq[i]=seq[i].replace(\"'\",'',100)\n",
    "        if '.' in seq[i]:\n",
    "            seq[i]=seq[i].replace('.','',100)\n",
    "        if ',' in seq[i]:\n",
    "            seq[i]=seq[i].replace(',','',100)\n",
    "        if ',' in seq[i]:\n",
    "            seq[i]=seq[i].replace('\"','',100)\n",
    "        if '``' in seq[i]:\n",
    "            seq[i]=seq[i].replace('``','',100)\n",
    "            \n",
    "    seq=['<start>']+seq+['<end>']\n",
    "    out_seq=' '\n",
    "    out_tag=' '\n",
    "    out_seq=out_seq.join(seq)\n",
    "    \n",
    "    tag=['<start>']+tag+['<end>']\n",
    "    out_tag=out_tag.join(tag)\n",
    "    seq_file.write(out_seq)\n",
    "    seq_file.write('\\n')\n",
    "    tag_file.write(out_tag)\n",
    "    tag_file.write('\\n')\n",
    "\n",
    "\n",
    "seq_file.close()\n",
    "tag_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ce59b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_file=open(\"tag.txt\",\"r\")\n",
    "seq_file = open(\"seq.txt\",\"r\")\n",
    "train_seq=open(\"seq_train.txt\",\"w\")\n",
    "train_tag=open(\"tag_train.txt\",\"w\")\n",
    "seq_file.seek(0)\n",
    "tag_file.seek(0)\n",
    "word_dict={'<start>':0}\n",
    "tag_dict={'<start>':0}\n",
    "word_count=1\n",
    "tag_count=1\n",
    "for i in range(train_nos):\n",
    "    temp=seq_file.readline().split(' ')\n",
    "    out=' '\n",
    "    for word in temp:\n",
    "        if word not in word_dict:\n",
    "            word_dict[word]=word_count\n",
    "            word_count+=1\n",
    "    x=[str(word_dict[word]) for word in temp]\n",
    "    out=out.join(x)\n",
    "    train_seq.write(out)\n",
    "    train_seq.write('\\n')\n",
    "    temp=tag_file.readline().split(' ')\n",
    "    out=' '\n",
    "    for tag in temp:\n",
    "        if tag not in tag_dict:\n",
    "            tag_dict[tag]=tag_count\n",
    "            tag_count+=1\n",
    "    x=[str(tag_dict[tag]) for tag in temp]\n",
    "    out=out.join(x)\n",
    "    train_tag.write(out)\n",
    "    train_tag.write('\\n')\n",
    "test_tag=open('test_tag.txt','w')\n",
    "test_seq=open('test_seq.txt','w')\n",
    "for j in range(train_nos,len(data)):\n",
    "    temp_seq=seq_file.readline()\n",
    "    temp_tag=tag_file.readline()\n",
    "    test_tag.write(temp_tag)\n",
    "    #test_tag.write('\\n')\n",
    "    test_seq.write(temp_seq)\n",
    "    #test_seq.write('\\n')\n",
    "train_tag.close()\n",
    "train_seq.close()\n",
    "tag_file.close()\n",
    "seq_file.close()\n",
    "test_tag.close()\n",
    "test_seq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "879b4faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_file=open('tag.txt','r')\n",
    "for i in range(len(data)):\n",
    "    temp=tag_file.readline().split(' ')\n",
    "    for tag in temp:\n",
    "            if tag not in tag_dict:\n",
    "                tag_dict[tag]=tag_count\n",
    "                tag_count+=1\n",
    "tag_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9cf8f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "emit=np.zeros([word_count,tag_count])\n",
    "emit_con=np.zeros([word_count,tag_count,tag_count])\n",
    "trans=np.zeros([tag_count,tag_count])\n",
    "trans_tri=np.zeros([tag_count,tag_count,tag_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1625aa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq1=open('seq_train.txt','r')\n",
    "train_seq=train_seq1.readlines()\n",
    "train_tag1=open('tag_train.txt','r')\n",
    "train_tag=train_tag1.readlines()\n",
    "for i in range(len(train_seq)):\n",
    "    seq=[int(j) for j in train_seq[i].split()]\n",
    "    tag=[int(j) for j in train_tag[i].split()]\n",
    "    for j in range(len(seq)):\n",
    "        emit[seq[j]][tag[j]]+=1\n",
    "    for j in range(1,len(seq)):\n",
    "        trans[tag[j]][tag[j-1]]+=1\n",
    "        \n",
    "    for j in range(2,len(seq)):\n",
    "        emit_con[seq[j]][tag[j-1]][tag[j-2]]+=1\n",
    "        trans_tri[tag[j]][tag[j-1]][tag[j-2]]+=1\n",
    "train_seq1.close()\n",
    "train_tag1.close()\n",
    "#print(trans_tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f71ea3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-8da94e501538>:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  trans/=np.sum(trans,axis=0)\n",
      "<ipython-input-8-8da94e501538>:5: RuntimeWarning: invalid value encountered in true_divide\n",
      "  emit_con[i]/=np.sum(emit_con[i],axis=0)\n",
      "<ipython-input-8-8da94e501538>:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  trans_tri[i]/=np.sum(trans_tri[i],axis=0)\n"
     ]
    }
   ],
   "source": [
    "emit/=np.sum(emit,axis=0)\n",
    "trans/=np.sum(trans,axis=0) \n",
    "x,y,z=emit_con.shape\n",
    "for i in range(x):\n",
    "    emit_con[i]/=np.sum(emit_con[i],axis=0)\n",
    "x,y,z=trans_tri.shape\n",
    "for i in range(x):\n",
    "    trans_tri[i]/=np.sum(trans_tri[i],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be417fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b0aee1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing words is:  1820\n"
     ]
    }
   ],
   "source": [
    "test_seq=open(\"test_seq.txt\",'r')\n",
    "test_seq.seek(0)\n",
    "missing=0\n",
    "for line in test_seq:\n",
    "    for word in line.split(' '):\n",
    "        if word not in word_dict:\n",
    "            missing+=1\n",
    "print('Number of missing words is: ',missing)\n",
    "test_seq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f54f7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> the latest 10-year notes were quoted at 100 22/32 to yield 788% compared with 100 16/32 to yield 790% <end>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_seq=open(\"test_seq.txt\",'r')\n",
    "test_seq.seek(0)\n",
    "print(test_seq.readline())\n",
    "test_seq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af0efef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_tag_num=word_dict['<start>']\n",
    "end_tag_num=tag_dict['<end>\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77e01320",
   "metadata": {},
   "outputs": [],
   "source": [
    "class node:\n",
    "    \n",
    "    def __init__(self,tag_num,word,index):\n",
    "        self.tag_num=tag_num\n",
    "        self.word=word\n",
    "        self.emit_prob=0\n",
    "        self.bi=None\n",
    "        self.tri=None\n",
    "        self.prob=0\n",
    "        self.tri=None\n",
    "        self.index=index\n",
    "        \n",
    "        if self.word not in word_dict:\n",
    "            self.emit_prob=1\n",
    "            self.tag_num=tag_dict[most_used_tag]\n",
    "        else:\n",
    "            self.emit_prob=emit[word_dict[word]][self.tag_num]\n",
    "            \n",
    "class timestep:\n",
    "    def __init__(self,word,index):\n",
    "        self.word=word\n",
    "        self.index=index\n",
    "        self.node_list=[]\n",
    "        self.probable_nodes=[]#list to store top 3 nodes \n",
    "        if word in word_dict:\n",
    "            for i in range(tag_count):\n",
    "                if emit[word_dict[word]][i]>0:\n",
    "                    obj=node(tag_num=i,word=self.word,index=self.index)#tag_num,word,index.\n",
    "                    self.node_list.append(obj)\n",
    "        else:\n",
    "            obj=node(tag_num=3,word=self.word,index=self.index)#tag_num,word,index.\n",
    "            self.node_list.append(obj)\n",
    "            \n",
    "        #print(len(self.node_list),self.word)\n",
    "\n",
    "class timeline:\n",
    "    def __init__(self,seq):\n",
    "        self.seq=seq\n",
    "        self.tag_count=tag_count\n",
    "        self.timesteps=[]\n",
    "        for i in range(len(self.seq)):\n",
    "            self.timesteps.append(timestep(word=seq[i],index=i))#word, index\n",
    "        #print(len(self.timesteps))\n",
    "            \n",
    "    def trigram(self):\n",
    "        #index0,1,2\n",
    "        node1list=self.timesteps[1].node_list\n",
    "        for node1 in node1list:\n",
    "            node1.prob=node1.emit_prob*trans[node1.tag_num][tag_dict['<start>']]\n",
    "            node1.tri=self.timesteps[0].node_list[0]\n",
    "            #print(node1.prob)\n",
    "        node2list=self.timesteps[2].node_list\n",
    "        for node2 in node2list:\n",
    "            node1list=self.timesteps[1].node_list\n",
    "            temp=0\n",
    "            temp_obj=None\n",
    "            for node1 in node1list:\n",
    "                resultant_prob=node2.emit_prob*trans[node2.tag_num][node1.tag_num]*node1.prob\n",
    "                if resultant_prob==0:\n",
    "                    resultant_prob=0.000000000000000001\n",
    "                if resultant_prob>temp:\n",
    "                    temp_obj=node1\n",
    "                    temp=resultant_prob\n",
    "            node2.tri=temp_obj\n",
    "            node2.prob=temp\n",
    "            #print(node2.prob)\n",
    "                    \n",
    "        for i in range(3,len(self.timesteps)):\n",
    "            node2list=self.timesteps[i].node_list#current\n",
    "            temp=0\n",
    "            temp_obj=None\n",
    "            temp_prob=0\n",
    "            for node2 in node2list:\n",
    "                #print(node2.emit_prob)\n",
    "                node1list=self.timesteps[i-1].node_list#previous\n",
    "                for node1 in node1list:\n",
    "                    acc_prob=node1.prob\n",
    "                    #print(acc_prob)\n",
    "                    node0list=self.timesteps[i-2].node_list#previous to previous\n",
    "                    for node0 in node0list:\n",
    "                        if node2.word in word_dict:\n",
    "                            emit_prob=emit_con[word_dict[word]][node1.tag_num][node0.tag_num]\n",
    "                        else:\n",
    "                            emit_prob=1\n",
    "                        #print('emit_prob',' ' ,emit_prob)\n",
    "                        #print(trans_tri[node2.tag_num][node1.tag_num][node0.tag_num],)\n",
    "                        resultant_prob=acc_prob*emit_prob*trans_tri[node2.tag_num][node1.tag_num][node0.tag_num]\n",
    "                        #print(resultant_prob)\n",
    "                        if resultant_prob==0:\n",
    "                            resultant_prob=0.00000000000000000001\n",
    "                        if resultant_prob>temp_prob:\n",
    "                            temp_obj=node1\n",
    "                            temp_prob=resultant_prob\n",
    "                            #print(node2.index)\n",
    "                #print()\n",
    "                node2.tri=temp_obj\n",
    "                \n",
    "                node2.prob=temp_prob\n",
    "                \n",
    "                \n",
    "        last_ts=self.timesteps[-1].node_list#last character \n",
    "        temp=0\n",
    "        out_node=None\n",
    "        max_prob=[]\n",
    "        for node1 in last_ts:\n",
    "            #print(node1.word)\n",
    "            if node1.prob>temp:\n",
    "                temp=node1.prob\n",
    "                out_node=node1\n",
    "                #print(temp)\n",
    "        \n",
    "        out_tags=[]\n",
    "        current_node=out_node\n",
    "        while current_node:\n",
    "            out_tags.append(current_node.tag_num)\n",
    "            #print(current_node.index)\n",
    "            current_node=current_node.tri\n",
    "        out_tags=out_tags[::-1]    \n",
    "        return out_tags    \n",
    "    \n",
    "    def trigram_3(self):\n",
    "        #using probable node list in timestep class to store top 3 nodes\n",
    "        node1list=self.timesteps[1].node_list\n",
    "        for node1 in node1list:\n",
    "            node1.prob=node1.emit_prob*trans[node1.tag_num][tag_dict['<start>']]\n",
    "            node1.tri=self.timesteps[0].node_list[0]\n",
    "        node1list.sort(key=lambda obj: obj.prob)#sorting list to get top three nodes\n",
    "        if len(node1list)>=3:\n",
    "            self.timesteps[1].probable_nodes=node1list[0:3] \n",
    "        else:\n",
    "            self.timesteps[1].probable_nodes=node1list\n",
    "        node2list=self.timesteps[2].node_list\n",
    "        for node2 in node2list:\n",
    "            node1list=self.timesteps[1].node_list\n",
    "            temp=0\n",
    "            temp_obj=None\n",
    "            for node1 in node1list:\n",
    "                resultant_prob=node2.emit_prob*trans[node2.tag_num][node1.tag_num]*node1.prob\n",
    "                if resultant_prob==0:\n",
    "                    resultant_prob=0.000000000000000001\n",
    "                if resultant_prob>temp:\n",
    "                    temp_obj=node1\n",
    "                    temp=resultant_prob\n",
    "            node2.tri=temp_obj\n",
    "            node2.prob=temp\n",
    "        node2list.sort(key=lambda obj: obj.prob)#sorting list to get top three nodes\n",
    "        if len(node2list)>=3:\n",
    "            self.timesteps[2].probable_nodes=node2list[0:3] \n",
    "        else:\n",
    "            self.timesteps[2].probable_nodes=node2list\n",
    "                    \n",
    "        for i in range(3,len(self.timesteps)):\n",
    "            node2list=self.timesteps[i].node_list\n",
    "            temp=0\n",
    "            temp_obj=None\n",
    "            temp_prob=0\n",
    "            for node2 in node2list:\n",
    "                node1list=self.timesteps[i-1].node_list\n",
    "                for node1 in node1list:\n",
    "                    acc_prob=node1.prob\n",
    "                    node0list=self.timesteps[i-2].node_list\n",
    "                    for node0 in node0list:\n",
    "                        if node2.word in word_dict:\n",
    "                            emit_prob=emit_con[word_dict[word]][node1.tag_num][node0.tag_num]\n",
    "                        else:\n",
    "                            emit_prob=1\n",
    "                        resultant_prob=acc_prob*emit_prob*trans_tri[node2.tag_num][node1.tag_num][node0.tag_num]\n",
    "        \n",
    "                        if resultant_prob==0:\n",
    "                            resultant_prob=0.00000000000000000001\n",
    "                        if resultant_prob>temp_prob:\n",
    "                            temp_obj=node1\n",
    "                            temp_prob=resultant_prob\n",
    "            \n",
    "                node2.tri=temp_obj\n",
    "                node2.prob=temp_prob\n",
    "        node2list.sort(key=lambda obj: obj.prob)#sorting list to get top three nodes\n",
    "        if len(node2list)>=3:\n",
    "            self.timesteps[i].probable_nodes=node2list[0:3] \n",
    "        else:\n",
    "            self.timesteps[i].probable_nodes=node2list\n",
    "                \n",
    "        last_ts=self.timesteps[-1].node_list\n",
    "        temp=0\n",
    "        out_node=None\n",
    "        max_prob=[]\n",
    "        for node1 in last_ts:\n",
    "            if node1.prob>temp:\n",
    "                temp=node1.prob\n",
    "                out_node=node1\n",
    "        \n",
    "        out_tags=[]\n",
    "        current_node=out_node\n",
    "        while current_node:\n",
    "            out_tags.append(current_node.tag_num)\n",
    "            current_node=current_node.tri\n",
    "        out_tags=out_tags[::-1]    \n",
    "        return out_tags        \n",
    "                    \n",
    "                        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b4f6fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IN', 'JJ', 'NN', 'NN', 'NN', 'IN', 'NN', 'NN', 'NN', 'NN', 'NN', 'VBZ', 'JJ', 'NN', 'IN', 'JJ', 'NNS', 'VBD', 'RB', 'JJ', 'JJ', 'RB', 'NN', 'WRB', 'NNP', 'NN', 'NN', 'WP', 'VBZ', 'RB', 'VBP', 'PRP$', 'NNP', 'VB', 'VBD', 'JJ', 'VB', 'LS', 'NN', 'IN', 'NNS', 'IN', 'LS', 'NN', 'NN', 'VBP', 'NN']\n",
      "\n",
      "['IN', 'JJ', 'NN', 'NN', 'NN', 'IN', 'NN', 'NN', 'NN', 'NN', 'NN', 'VBZ', 'JJ', 'NN', 'IN', 'JJ', 'NNS', 'VBD', 'RB', 'JJ', 'JJ', 'RB', 'NN', 'WRB', 'NNP', 'NN', 'NN', 'WP', 'VBZ', 'RB', 'VBP', 'PRP$', 'NNP', 'VB', 'VBD', 'JJ', 'VB', 'LS', 'NN', 'IN', 'NNS', 'IN', 'LS', 'NN', 'NN', 'VBP', 'NN']\n"
     ]
    }
   ],
   "source": [
    "num_to_tag={val:key for key,val in tag_dict.items()}\n",
    "c='<start> that former sri lanka skipper and ace batsman aravinda se silva is a man of few words was very much evident on Wednesday when the legendary batsman who has always let his bat talk struggled to answer a barrage of questions at a function to_f promote <end>'\n",
    "c=c.split()\n",
    "\n",
    "t=timeline(c)\n",
    "out1=t.trigram_3()#using top3 nodes at eah time step\n",
    "out2=t.trigram()#using traditional viterbi\n",
    "out1=[num_to_tag[i] for i in out1]\n",
    "out2=[num_to_tag[i] for i in out2]\n",
    "print(out1[1::])\n",
    "print()\n",
    "print(out2[1::])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e69c7ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that IN\n",
      "former JJ\n",
      "sri NN\n",
      "lanka NN\n",
      "skipper NN\n",
      "and IN\n",
      "ace NN\n",
      "batsman NN\n",
      "aravinda NN\n",
      "se NN\n",
      "silva NN\n",
      "is VBZ\n",
      "a JJ\n",
      "man NN\n",
      "of IN\n",
      "few JJ\n",
      "words NNS\n",
      "was VBD\n",
      "very RB\n",
      "much JJ\n",
      "evident JJ\n",
      "on RB\n",
      "Wednesday NN\n",
      "when WRB\n",
      "the NNP\n",
      "legendary NN\n",
      "batsman NN\n",
      "who WP\n",
      "has VBZ\n",
      "always RB\n",
      "let VBP\n",
      "his PRP$\n",
      "bat NNP\n",
      "talk VB\n",
      "struggled VBD\n",
      "to JJ\n",
      "answer VB\n",
      "a LS\n",
      "barrage NN\n",
      "of IN\n",
      "questions NNS\n",
      "at IN\n",
      "a LS\n",
      "function NN\n",
      "to_f NN\n",
      "promote VBP\n"
     ]
    }
   ],
   "source": [
    "c=c[1::]\n",
    "out1=out1[1::]\n",
    "for i in range(len(out1[1::])):\n",
    "    print(c[i],out1[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53f4f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6516a2a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ed3021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcd32f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
